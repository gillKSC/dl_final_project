Downloading (…)okenizer_config.json:   0%|                                                                                                                                                     | 0.00/28.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 2.55kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                                                                                                                                     | 0.00/232k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 3.79MB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                                                                                                     | 0.00/466k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 23.3MB/s]
Downloading (…)lve/main/config.json:   0%|                                                                                                                                                      | 0.00/483 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 327kB/s]
True
Specified arguments: Namespace(batch_size=16, device='cuda', experiment='overfit', lr=0.0001, model='distilbert-base-uncased', num_epochs=5, small_subset='false', type_classification='binary')
training data point 24245
validation data point 3463
teting data point 6928
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Downloading pytorch_model.bin:   0%|                                                                                                                                                           | 0.00/268M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|█████▋                                                                                                                                            | 10.5M/268M [00:00<00:04, 61.9MB/s]Downloading pytorch_model.bin:  12%|█████████████████▏                                                                                                                                | 31.5M/268M [00:00<00:02, 97.3MB/s]Downloading pytorch_model.bin:  20%|████████████████████████████▊                                                                                                                      | 52.4M/268M [00:00<00:02, 106MB/s]Downloading pytorch_model.bin:  27%|████████████████████████████████████████▎                                                                                                          | 73.4M/268M [00:00<00:01, 110MB/s]Downloading pytorch_model.bin:  35%|███████████████████████████████████████████████████▊                                                                                               | 94.4M/268M [00:00<00:01, 112MB/s]Downloading pytorch_model.bin:  43%|███████████████████████████████████████████████████████████████▋                                                                                    | 115M/268M [00:01<00:01, 113MB/s]Downloading pytorch_model.bin:  51%|███████████████████████████████████████████████████████████████████████████▎                                                                        | 136M/268M [00:01<00:01, 115MB/s]Downloading pytorch_model.bin:  59%|██████████████████████████████████████████████████████████████████████████████████████▊                                                             | 157M/268M [00:01<00:00, 115MB/s]Downloading pytorch_model.bin:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 178M/268M [00:01<00:00, 115MB/s]Downloading pytorch_model.bin:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 199M/268M [00:01<00:00, 116MB/s]Downloading pytorch_model.bin:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 220M/268M [00:01<00:00, 116MB/s]Downloading pytorch_model.bin:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 241M/268M [00:02<00:00, 115MB/s]Downloading pytorch_model.bin:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 262M/268M [00:02<00:00, 116MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:02<00:00, 112MB/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Downloading builder script:   0%|                                                                                                                                                             | 0.00/4.20k [00:00<?, ?B/s]Downloading builder script: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.20k/4.20k [00:00<00:00, 2.30MB/s]